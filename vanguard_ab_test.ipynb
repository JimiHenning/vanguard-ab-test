{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f012f3-d953-4bab-8d90-46a953e03637",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import vanguard_functions as vf\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "from statsmodels.stats.proportion import proportions_ztest\n",
    "from scipy.stats import chi2_contingency\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a7848d-d3a9-4892-b7ef-5924959ef90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53435ce4-3efd-45a1-88d2-dc445451707b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pt1 = pd.read_csv('df_final_web_data_pt_1.txt')\n",
    "df_pt2 = pd.read_csv('df_final_web_data_pt_2.txt')\n",
    "df_experi = pd.read_csv('df_final_experiment_clients.txt')\n",
    "df_demo = pd.read_csv('df_final_demo.txt')\n",
    "\n",
    "\n",
    "pd.set_option('display.max_rows',1000)\n",
    "pd.set_option('display.max_columns', 90)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81f13d3-4c5a-4f09-86d5-a061fce65ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pt1.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad5137a-8d75-4dd3-813b-53340bde758b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pt2.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ca91fd-3aee-47f4-be42-0ab859d63d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine original 3 data files: df_pt1 + df_pt2 + final_experiment \n",
    "df_12 = pd.concat([df_pt1,df_pt2],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ca667e-e0d8-4359-94aa-dba59f17161a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vf.strip_replace_ws (df_demo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811f8069-4a61-4818-8356-4e4314887780",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_demo.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf18a87-06f4-4f76-8daf-4713402705c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop null values\n",
    "df_demo = df_demo.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0aecddb-2a1c-4710-b4c4-98194a53256b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_demo.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a93a0f-6aa5-4eef-a0ce-592d0da038e4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#rename and homogenize column names\n",
    "column_replacements = {\"gendr\":\"gender\", \"bal\":\"acct_balance\", \"clnt_tenure_yr\":\"tenure_years\",\"clnt_tenure_mnth\":\"tenure_months\",\"clnt_age\":\"age\"}\n",
    "vf.rename_columns (df_demo, column_replacements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a8da17-489b-4c35-9cd8-9dd89c77f9a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#recasting whole number columns to integer\n",
    "vf.recast(df_demo, 'tenure_years','tenure_months','num_accts','calls_6_mnth','logons_6_mnth','age')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46db0251-35cb-4ff9-950c-6288748542bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_demo['gender'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899507dd-9761-4243-a342-812d30ec9688",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merging and renaming Unknown gender rows\n",
    "df_demo['gender'] = df_demo['gender'].replace({\"X\":\"Unknown\",\"U\":\"Unknown\"})\n",
    "df_demo['gender'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10e7dd1-83eb-4cfb-b52b-861584a499b9",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743a64fd-a74d-41a7-9d60-87cb53574f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#analysing the age ditribution of the clients\n",
    "print(df_demo['age'].describe())\n",
    "print() \n",
    "print(f\"The mode of client age:\\n{df_demo['age'].mode()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a64145-fb44-4e1d-90ab-8a596e2168d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(df_demo['age'], kde=False, color='blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09bd1793-1056-4649-985b-26b086d2a448",
   "metadata": {},
   "outputs": [],
   "source": [
    "#very strange age distribution, binning to smooth out the effect!\n",
    "\n",
    "# Creating age bins:\n",
    "bin_labels = [f'{i}-{i+5}' for i in range(0, 100, 5)]\n",
    "df_demo['age_binned'] = pd.cut(df_demo['age'], bins=range(0, 101, 5), labels=bin_labels, right=False, ordered=True)\n",
    "\n",
    "# Plot the binned data,sorted\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(df_demo['age_binned'], discrete=True, kde=False)\n",
    "plt.xticks(rotation=45)\n",
    "plt.title(\"Binned Age Distribution (5-year bins)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a7615c-f948-4754-b0f7-5f5ce3ebbe06",
   "metadata": {},
   "source": [
    "As we can see, we have a bimodal distribution with most clients being either between 30-35 or 50-55 years old, with the mean and median being both around 47 years meaning most clients tend to be above middle age."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19f39c6-74a7-4fc8-a332-cd5555209b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualising the gender distribution of the clients\n",
    "df_demo['gender'].value_counts().plot.pie(autopct='%1.1f%%', startangle=90, colors=sns.color_palette(\"Set3\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35bc605-c6d1-44fe-bcba-30125617c494",
   "metadata": {},
   "source": [
    "As we can see, we have a relatively even gender distribution between male, female and unknown, each about a third of the clients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc6ba35-3a88-4923-9ca0-658990155b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#analysing the tenure of clients\n",
    "print(df_demo['tenure_years'].describe())\n",
    "print() \n",
    "print(f\"The mode of tenure years:\\n{df_demo['tenure_years'].mode()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99908c65-c8dd-4bd9-810b-ceca586af58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(df_demo['tenure_years'], kde=True, color='blue')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9d47cb-a42f-486c-a4bc-21c779b33148",
   "metadata": {},
   "source": [
    "As we can see, most users tend to have been clients for around 6 years, with the tenure mean at 12 and the median at 11 years meaning over 50% longstanding users with more than 11 years tenure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c461def-8bd2-46ca-b4b6-fc88a1cf2310",
   "metadata": {},
   "outputs": [],
   "source": [
    "#analysing the amount of money in customer accounts\n",
    "pd.options.display.float_format = '{:.4f}'.format\n",
    "df_demo[\"acct_balance\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7863a552-556c-41f9-9838-3bcec1750de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "sns.histplot(df_demo['acct_balance'], kde=True, color='blue')\n",
    "\n",
    "# Format y-axis to avoid scientific notation\n",
    "plt.gca().yaxis.set_major_formatter(FuncFormatter(lambda x, _: f'{int(x):,}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df04283b-4d79-4fac-8d3e-a2802d252a23",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_demo.sort_values(by='acct_balance',ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00af3735-3285-43aa-89eb-3cdd6c39fca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data = df_demo['acct_balance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b105d752-1f0b-47d9-8ea5-b0580b6cbb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing massive outliers\n",
    "df_acct_no_outlier = df_demo[(df_demo['acct_balance'] <= df_demo['acct_balance'].quantile(0.95))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab96b567-d004-4a09-874c-3757e5428f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "sns.histplot(df_acct_no_outlier['acct_balance'], kde=True, color='blue')\n",
    "\n",
    "# Format y-axis to avoid scientific notation\n",
    "plt.gca().yaxis.set_major_formatter(FuncFormatter(lambda x, _: f'{int(x):,}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47bc7746-2e7c-4692-89c1-dec5f0518da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#analysing account balance by gender\n",
    "df_demo.groupby(\"gender\").agg({\"acct_balance\":[\"mean\", \"median\",\"max\",\"min\",\"std\"]}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca28b12d-a363-421f-a87d-42b6dd5e3ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=df_demo, x='gender', y='acct_balance', palette=\"coolwarm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f398c202-11a5-4123-b2e2-23a70f5ab302",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=df_acct_no_outlier, x='gender', y='acct_balance', palette=\"coolwarm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9162d9-f25d-46ef-b569-14ee728b39a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_acct_no_outlier.groupby(\"gender\").agg({\"acct_balance\":[\"mean\", \"median\",\"max\",\"min\",\"std\"]}).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71936695-4c6a-4299-8681-4e411f3f08b1",
   "metadata": {},
   "source": [
    "As we can see, we have a heavily positively skewed distribution, we had to remove extreme outliers to get a readable visualisation. The mean sits at 147446 while the median is significantly lower at 63334. Gender-wise it seems relatively evenly distributed with men being a bit higher, after removing extreme outliers, which all belonged to men. People with unknown gender have a significantly lower mean and median."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8bcca3-cd29-49ba-ba45-1b566a6d0d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#analysing tenure by gender\n",
    "sns.boxplot(data=df_demo, x='gender', y='tenure_years', palette=\"coolwarm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42467c9f-df86-4443-8412-f69262d63442",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_demo.groupby(\"gender\").agg({\"tenure_years\":[\"mean\", \"median\",\"max\",\"min\",\"std\"]}).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266e804d-d76e-4ffb-b6ce-cfb100cb332a",
   "metadata": {},
   "source": [
    "Men and women also appear to be similarly longstanding customers, while people with unknown gender tend to be relatively new customers. This makes sense considering that longstanding customers would have more interactions with the staff where at some point their gender would be stated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e9d06f-a75b-4306-9f59-422152ec0c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping rows that were not part of either the control or test group\n",
    "df_experi_nonan = df_experi.dropna(subset=['Variation'])\n",
    "df_experi_nonan.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c2e95d-e512-488b-92e4-280d24f751ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merging the experiment dataframes\n",
    "df_merged_12_experi = pd.merge(df_12,df_experi_nonan, on='client_id',how='inner')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6297dc-09fe-4de8-ad4f-79517b84f2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#showing duplicates\n",
    "duplicates = df_merged_12_experi[df_merged_12_experi.duplicated(keep=False)]\n",
    "duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e7a82c-4edc-4870-8daf-90478bdb30a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping duplicates \n",
    "df_merged_unique = df_merged_12_experi.drop_duplicates(keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23820f35-bc62-4f3b-8849-11d22d2a0813",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merging experiment data with client data\n",
    "df_merged_unique_demo = pd.merge(df_merged_unique,df_demo, on='client_id',how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3003a26-4a92-42d5-bb14-4c6150d77085",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged_unique_demo.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c785a6b6-01a8-4ec5-b7ab-5ce420f2534b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#renaming\n",
    "df_all = df_merged_unique_demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f966ef3-d7c9-47a3-94d5-a2cd802a0954",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dividing the dataframe into test and control dataframes\n",
    "df_control = df_all[df_all['Variation'] == \"Control\"]\n",
    "df_test = df_all[df_all['Variation'] == \"Test\"]\n",
    "df_control = df_control.reset_index(drop=True)\n",
    "df_test = df_test.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a670b3-2081-439e-9ae9-90e613869d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set all numbers display in normal format\n",
    "pd.options.display.float_format ='{:,.4f}'.format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ca116b-6225-45a1-91f4-d25080e6966d",
   "metadata": {},
   "source": [
    "## KPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84ead74-4408-40ba-84f9-c2310969bb0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate completion rate for control group\n",
    "completion_rate_control = vf.calculate_completion_rate(df_control)\n",
    "print(f\"Completion rate for control group: {completion_rate_control}%\")\n",
    "\n",
    "# Calculate completion rate for test group\n",
    "completion_rate_test = vf.calculate_completion_rate(df_test)\n",
    "print(f\"Completion rate for test group: {completion_rate_test}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf314d8-39b6-4d04-a5ec-939b296e713f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Completion rates visualisation\n",
    "completion_rates = {\n",
    "    'Group': ['Test', 'Control'],\n",
    "    'Completion Rate (%)': [completion_rate_test, completion_rate_control]\n",
    "}\n",
    "\n",
    "completion_df = pd.DataFrame(completion_rates)\n",
    "\n",
    "custom_palette = {'Control': 'lightcoral', 'Test': 'skyblue'}\n",
    "\n",
    "plt.figure(figsize=(3, 6))\n",
    "bar_plot = sns.barplot(x='Group', y='Completion Rate (%)', data=completion_df, palette=custom_palette)\n",
    "\n",
    "plt.title('Completion Rates for Test and Control Group')\n",
    "plt.xlabel('Group')\n",
    "plt.ylabel('Completion Rate (%)')\n",
    "plt.ylim(0, 100)  # Set y-axis limits from 0 to 100\n",
    "\n",
    "# Annotate each bar with the completion rate\n",
    "for p in bar_plot.patches:\n",
    "    bar_plot.annotate(f'{p.get_height():.2f}%', \n",
    "                      (p.get_x() + p.get_width() / 2., p.get_height()), \n",
    "                      ha='center', va='bottom', \n",
    "                      fontsize=10, color='black', \n",
    "                      xytext=(0, 5), \n",
    "                      textcoords='offset points')\n",
    "\n",
    "plt.savefig('completion_rates_plot.png', bbox_inches='tight', dpi=300)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07e7cd3-6529-4dfe-8c0f-dd6b547f1f3e",
   "metadata": {},
   "source": [
    "The completion rate in the new design appears to be significantly higher than in the old design."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4fb6b6-360c-46ec-b10a-3ea2b16471ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate error rates:\n",
    "step_order_dict = {0: 'start', 1: 'step_1', 2: 'step_2', 3: 'step_3', 4: 'confirm'}\n",
    "\n",
    "df_test, total_errors_test, error_rate_test = vf.calculate_error_rate(df_test, step_mapping=step_order_dict)\n",
    "df_control, total_errors_control, error_rate_control = vf.calculate_error_rate(df_control,step_mapping=step_order_dict)\n",
    "\n",
    "print(f\"Total errors in test group: {total_errors_test}\")\n",
    "print(f\"Error rate for test group: {error_rate_test}%\")\n",
    "print()\n",
    "print(f\"Total errors in control group: {total_errors_control}\")\n",
    "print(f\"Error rate for control group: {error_rate_control}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8289eecf-7611-4b66-896c-3b9cb14ca39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Error rates visualisation\n",
    "error_rates = {\n",
    "    'Group': ['Test', 'Control'],\n",
    "    'Error Rate (%)': [error_rate_test, error_rate_control]\n",
    "}\n",
    "\n",
    "error_df = pd.DataFrame(error_rates)\n",
    "\n",
    "custom_palette = {'Control': 'lightcoral', 'Test': 'skyblue'}\n",
    "\n",
    "\n",
    "plt.figure(figsize=(3, 6))\n",
    "bar_plot = sns.barplot(x='Group', y='Error Rate (%)', data=error_df, palette=custom_palette)\n",
    "\n",
    "\n",
    "plt.title('Error Rates for Test and Control Groups')\n",
    "plt.xlabel('Group')\n",
    "plt.ylabel('Error Rate (%)')\n",
    "plt.ylim(0, 100)  # Set y-axis limits from 0 to 100\n",
    "\n",
    "# Annotate each bar with the error rate\n",
    "for p in bar_plot.patches:\n",
    "    bar_plot.annotate(f'{p.get_height():.2f}%', \n",
    "                      (p.get_x() + p.get_width() / 2., p.get_height()), \n",
    "                      ha='center', va='bottom', \n",
    "                      fontsize=10, color='black', \n",
    "                      xytext=(0, 5), \n",
    "                      textcoords='offset points')\n",
    "\n",
    "plt.savefig('error_rates_plot.png', bbox_inches='tight', dpi=300)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160aacb6-a756-40d6-8b0e-30b8c7069582",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total errors and actions for control group\n",
    "total_errors_control = df_control['errors'].sum()\n",
    "total_actions_control = df_control.shape[0]\n",
    "\n",
    "# Total errors and actions for test group\n",
    "total_errors_test = df_test['errors'].sum()\n",
    "total_actions_test = df_test.shape[0]\n",
    "\n",
    "# Number of errors and total actions for both groups\n",
    "errors = np.array([total_errors_control, total_errors_test])\n",
    "actions = np.array([total_actions_control, total_actions_test])\n",
    "\n",
    "# Perform the two-proportion z-test\n",
    "z_stat, p_value = proportions_ztest(count=errors, nobs=actions)\n",
    "\n",
    "# Output the z-statistic and p-value\n",
    "print(f\"Z-statistic: {z_stat}\")\n",
    "print(f\"P-value: {p_value}\")\n",
    "\n",
    "# Interpretation of results\n",
    "alpha = 0.05  \n",
    "if p_value < alpha:\n",
    "    print(\"The difference in error rates between control and test groups is statistically significant.\")\n",
    "else:\n",
    "    print(\"The difference in error rates between control and test groups is not statistically significant.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16bf6c82-b319-4153-989b-eef03f647695",
   "metadata": {},
   "source": [
    "The error rate in the new design appears to be higher than in the old design."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f3c6c2-f9af-4976-8e69-910b0e3e5bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#analyse the time spent on each step\n",
    "df_control_timesort = vf.calculate_time_spent_per_step(df_control)\n",
    "df_test_timesort = vf.calculate_time_spent_per_step(df_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d87d23-03a6-4a00-89fa-7556680133c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_control_timesort.groupby('process_step')['time_spent_seconds'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8e56e3-1431-4909-9ba6-ab7d5463be6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_timesort.groupby('process_step')['time_spent_seconds'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29f4587-8a91-4588-8b00-87c1f16c7a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing outliers\n",
    "df_control_timesort_no_outliers = vf.tukeys_test_outliers(df_control_timesort,'time_spent_seconds', method = 'delete')\n",
    "df_test_timesort_no_outliers = vf.tukeys_test_outliers(df_test_timesort,'time_spent_seconds', method = 'delete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b304edde-591f-4780-be30-2f321d1dcf3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_control_timesort_no_outliers.groupby('process_step')['time_spent_seconds'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ee8cb9-24a9-41ed-9b28-6ad1c3f3b38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_timesort_no_outliers.groupby('process_step')['time_spent_seconds'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70980a4-4282-4ba8-a542-4ff257f03231",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_control = df_control_timesort_no_outliers.groupby('process_step')['time_spent_seconds'].mean().reset_index()\n",
    "mean_control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2da32b7-61dc-4b0b-91bc-0a2da8950ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_test = df_test_timesort_no_outliers.groupby('process_step')['time_spent_seconds'].mean().reset_index()\n",
    "mean_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb7bb4a-18af-468b-a2d4-beaa0f59d5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#steps to compare\n",
    "steps = ['start', 'step_1', 'step_2', 'step_3', 'confirm']\n",
    "\n",
    "# Perform t-tests for each step\n",
    "for step in steps:\n",
    "    # Get time spent on the current step for the control group\n",
    "    control_times = df_control_timesort_no_outliers[df_control_timesort_no_outliers['process_step'] == step]['time_spent_seconds']\n",
    "    \n",
    "    # Get time spent on the current step for the test group\n",
    "    test_times = df_test_timesort_no_outliers[df_test_timesort_no_outliers['process_step'] == step]['time_spent_seconds']\n",
    "    \n",
    "    # Ensure the times are numeric and drop NaN values\n",
    "    control_times = pd.to_numeric(control_times, errors='coerce').dropna()\n",
    "    test_times = pd.to_numeric(test_times, errors='coerce').dropna()\n",
    "    \n",
    "    # Check if either group is empty\n",
    "    if control_times.empty or test_times.empty:\n",
    "        print(f\"Insufficient data for step: {step} (control: {len(control_times)}, test: {len(test_times)})\")\n",
    "        continue\n",
    "    \n",
    "    # Debugging: Print the number of data points for each group\n",
    "    print(f\"{step.capitalize()} - Control group size: {len(control_times)}, Test group size: {len(test_times)}\")\n",
    "    \n",
    "    # Perform Welch's t-test (does not assume equal variances)\n",
    "    t_stat, p_value = stats.ttest_ind(control_times, test_times, equal_var=False)\n",
    "    \n",
    "    # Output the t-statistic and p-value for each step\n",
    "    print(f\"{step.capitalize()} - t-statistic: {t_stat}, p-value: {p_value}\")\n",
    "\n",
    "    alpha = 0.05  \n",
    "    if p_value < alpha:\n",
    "        print(f\"Difference in {step} time is statistically significant.\\n\")\n",
    "    else:\n",
    "        print(f\"No significant difference in {step} time.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a45a81-4999-42ac-958b-1c4beaea5f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 'Group' column for both DataFrames\n",
    "mean_control['Group'] = 'Control'\n",
    "mean_test['Group'] = 'Test'\n",
    "\n",
    "# Combine the two DataFrames\n",
    "combined_df = pd.concat([mean_test, mean_control])\n",
    "\n",
    "# Define the order of process steps excluding 'confirm'\n",
    "order = ['start', 'step_1', 'step_2', 'step_3']\n",
    "\n",
    "# Filter out the 'confirm' step from the combined DataFrame\n",
    "combined_df = combined_df[combined_df['process_step'] != 'confirm']\n",
    "\n",
    "# Create a custom color palette\n",
    "custom_palette = {'Control': 'lightcoral', 'Test': 'skyblue'}\n",
    "\n",
    "# Create the side-by-side bar plot\n",
    "plt.figure(figsize=(7, 3))\n",
    "sns.barplot(data=combined_df, x='process_step', y='time_spent_seconds', hue='Group', \n",
    "            palette=custom_palette, order=order)\n",
    "\n",
    "# Add titles and labels\n",
    "plt.title('Time Spent by Process Step for Test and Control Groups')\n",
    "plt.xlabel('Process Step')\n",
    "plt.ylabel('Time Spent (seconds)')\n",
    "\n",
    "# Add legend\n",
    "plt.legend(title='Group')\n",
    "\n",
    "# Save the plot as an image\n",
    "plt.savefig('time_spent_plot.png', bbox_inches='tight', dpi=300)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a342f6-e324-4cd2-96d5-3b54d9d4a24f",
   "metadata": {},
   "source": [
    "There is a statistically significant difference between the test and control groups for time spent, but they are practically very small differences, except for the last step where the control group spent significantly less time. At the start, at step 2 and step 3 the test group fared better, but at step 1 and the confirm step the control group needed less time. Overall a mixed result."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49bcfa0d-6a93-406d-8b2e-312b8ce3a282",
   "metadata": {},
   "source": [
    "## HYPOTHESIS TESTING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7e7545-d850-4d91-ba68-3d7794f7e25e",
   "metadata": {},
   "source": [
    "H0: The updated design did not improve the completion rate\n",
    "\n",
    "H1: The updated design led to a higher completion rate\n",
    "\n",
    "Significance level (α): 0.05\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ad95df-ae0e-4aba-b2e0-744c9fa5d328",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate completion rate for control group\n",
    "completion_rate_control = vf.calculate_completion_rate(df_control)\n",
    "print(f\"Completion rate for control group: {completion_rate_control}%\")\n",
    "\n",
    "# Calculate completion rate for test group\n",
    "completion_rate_test = vf.calculate_completion_rate(df_test)\n",
    "print(f\"Completion rate for test group: {completion_rate_test}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7346eaeb-0371-4d36-a8ee-9f9fe83624a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of users who completed the process (confirm) in control and test groups\n",
    "cfm_user_control = df_control[df_control['process_step'] == 'confirm']['visit_id'].nunique()\n",
    "cfm_user_test = df_test[df_test['process_step'] == 'confirm']['visit_id'].nunique()\n",
    "\n",
    "# Total number of users in control and test groups\n",
    "total_users_control = df_control['visit_id'].nunique()\n",
    "total_users_test = df_test['visit_id'].nunique()\n",
    "\n",
    "# Number of successes (confirmed users) for both groups\n",
    "successes = [cfm_user_test, cfm_user_control]\n",
    "\n",
    "# Number of total users in both groups\n",
    "nobs = [total_users_test, total_users_control]\n",
    "\n",
    "# Perform the z-test for proportions\n",
    "test_stat, p_value = proportions_ztest(successes, nobs)\n",
    "\n",
    "print(f\"Z-statistic: {test_stat}\")\n",
    "print(f\"P-value: {p_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7d6406-4e0f-4c76-976c-e569a99937e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.proportion import proportions_ztest\n",
    "\n",
    "# Perform the z-test for proportions (two-tailed by default)\n",
    "test_stat, p_value = proportions_ztest(successes, nobs)\n",
    "\n",
    "# For a one-tailed test, if the test statistic is positive, divide the p-value by 2\n",
    "if test_stat > 0:\n",
    "    one_tailed_p_value = p_value / 2\n",
    "else:\n",
    "    one_tailed_p_value = 1 - p_value / 2  # if negative, it's in the opposite direction\n",
    "\n",
    "print(f\"Z-statistic: {test_stat}\")\n",
    "print(f\"One-tailed P-value: {one_tailed_p_value}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d761c33-215a-4890-a265-20d09bd4e1ef",
   "metadata": {},
   "source": [
    "We reject the null-hypothesis (p-Value < 0.05, z_value more than 3 std away from the expected mean when H0 = true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf8ba27f-6e14-46a4-8a30-30d853c2a020",
   "metadata": {},
   "source": [
    "Threshold: Vanguard has set this minimum increase in completion rate at 5%. This is the rate at which the projected benefits, in terms of increased user engagement and potential revenue, are estimated to outweigh the costs of the new design.\r\n",
    "\n",
    "\n",
    "You are required to carry out another analysis, ensuring that the observed increase in completion rate from the A/B test meets or exceeds this 5% threshold. If the new design doesn’t lead to at least this level of improvement, it may not be justifiable from a cost perspective, regardless of its statistical significance%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489c2da9-8843-4468-a432-70f0632ea561",
   "metadata": {},
   "source": [
    "H0 : The new update did not result in an increas in completion rate of at least 5%.\n",
    "\n",
    "H1 : The new update did result in an increase in completion rate of at least 5%.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1793352c-5a9e-49ca-91c9-2a0ba765a23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#completion rate increase: \n",
    "comp_rate_increase = 58.52 - 49.84\n",
    "comp_rate_increase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b5579c-cba4-48ab-898c-251509f949bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the z-test for proportions for 5% threshhold\n",
    "test_stat, p_value = proportions_ztest(successes, nobs, value=0.05, alternative = \"larger\")\n",
    "\n",
    "print(f\"Z-statistic: {test_stat}\")\n",
    "print(f\"P-value: {p_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0800e752-3f80-4fad-acd2-c709453fa21b",
   "metadata": {},
   "source": [
    "The completion rate increase is around 8.68% which is significantly more than 5%, and the difference is statistically significant, meaning the new design is justifiable from a cost perspective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e334117-c2a4-4ff3-88b8-ffba71bc6ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_control['age'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974988b4-85f5-4ca8-8b51-df3915a1a222",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['age'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17345099-5f95-4775-9117-e42d81709749",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_control['tenure_years'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2afc3ccb-a060-444a-9a8e-a936a8470549",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['tenure_years'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325cf8c2-dd4f-433e-808d-42561f5131c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_control['gender'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b148a75-e500-4d08-a3dc-4b47ab73a3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['gender'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea00a4fb-569f-462e-904f-1afc9cdc0bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Design Effectiveness\n",
    "# Was the experiment well-structured?\n",
    "# Were clients randomly and equally divided between the old and new designs?\n",
    "# Were there any biases?\n",
    "\n",
    "# 1-both test and control group have the same data structure (same column names/ same value type per column) \n",
    "# 2- both groups had large and similar data size (test group 176699 rows/control group：140536 rows) \n",
    "\n",
    "# we collect all main key columns('gender','tenure_years','age', 'acct_balance','num_accts','calls_6_mnth','logons_6_mnth')  to test if any column \n",
    "# has distribution bias between test and control group\n",
    "# here we first test the category column 'gender' by Chi-square\n",
    "\n",
    "\n",
    "# H0: gender column are equally distributed \n",
    "# H1: gender column are not equally distributed \n",
    "\n",
    "gender_counts_control = df_control['gender'].value_counts()\n",
    "gender_counts_test = df_test['gender'].value_counts()\n",
    "contingency_table = pd.DataFrame({'Control': gender_counts_control, 'Test': gender_counts_test}).fillna(0)\n",
    "chi2, p, dof, expected = chi2_contingency(contingency_table)\n",
    "\n",
    "print(f\"Chi-square test statistic: {chi2}\")\n",
    "print(f\"P-value for gender distribution: {p} means it right to support H1: gender column are not equally distributed \")\n",
    "\n",
    "# then we further cross check above hypothesis for each gendr's percentage in both group and get contradictory result:\n",
    "# Control group : unknown 34.48%/ Male:33.75%/ Female:31.77% ///Test group : unknown33.51%/ Male:33.56%/ Female:32.93%\n",
    "# Very likely caused by a huge sample size which magnifies the minor differences in distribution in statistic\n",
    "\n",
    "print(df_control['gender'].value_counts(normalize=True)*100)\n",
    "print(df_test['gender'].value_counts(normalize=True)*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4bc16e4-dba7-4933-9655-c69c8b943ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gender counts for Control and Test groups\n",
    "gender_counts_control = df_control['gender'].value_counts()\n",
    "gender_counts_test = df_test['gender'].value_counts()\n",
    "\n",
    "# Total sample sizes for Control and Test groups\n",
    "n_control = len(df_control)\n",
    "n_test = len(df_test)\n",
    "\n",
    "# Perform z-test for each gender category\n",
    "for gender in ['M', 'F', 'Unknown']:\n",
    "    count_control = gender_counts_control.get(gender, 0)\n",
    "    count_test = gender_counts_test.get(gender, 0)\n",
    "    \n",
    "    # Combine the counts and sample sizes\n",
    "    counts = np.array([count_control, count_test])\n",
    "    nobs = np.array([n_control, n_test])\n",
    "    \n",
    "\n",
    "    z_stat, p_value = proportions_ztest(counts, nobs)\n",
    "    \n",
    "    print(f\"Gender: {gender}\")\n",
    "    print(f\"Z-statistic: {z_stat:.4f}, P-value: {p_value}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7eb28e-477a-432b-bc0c-ccb22ea04f13",
   "metadata": {},
   "source": [
    "We then decided to calculate **Cohen's h**, which is a common way to measure the **effect size** for comparing two proportions. It will help determine whether the differences in gender proportions are not only statistically significant but also practically significant.\r\n",
    "\r\n",
    "### Formula for Cohen's h:\r\n",
    "\r\n",
    "The formula for Cohen's h is:\r\n",
    "\r\n",
    "$$\r\n",
    "h = 2 \\times \\left( \\arcsin \\left( \\sqrt{p_1} \\right) - \\arcsin \\left( \\sqrt{p_2} \\right) \\right)\r\n",
    "$$\r\n",
    "\r\n",
    "Where:\r\n",
    "- \\( p_1 \\) is the proportion in the control group,\r\n",
    "- \\( p_2 \\) is the proportion in the test group.\r\n",
    "\r\n",
    "### Cohen's h Interpretation:\r\n",
    "- **0.2**: Small effect size\r\n",
    "- **0.5**: Medium effect size\r\n",
    "- **0.8**: Ln practical terms.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac85f12-7856-46a9-8898-dccefbab91d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proportions for each gender in control and test groups\n",
    "proportions_control = gender_counts_control / n_control\n",
    "proportions_test = gender_counts_test / n_test\n",
    "\n",
    "# Calculate Cohen's h for each gender category\n",
    "for gender in ['M', 'F', 'Unknown']:\n",
    "    p1 = proportions_control.get(gender, 0)\n",
    "    p2 = proportions_test.get(gender, 0)\n",
    "    \n",
    "    h = vf.cohen_h(p1, p2)\n",
    "    print(f\"Gender: {gender}, Cohen's h: {h:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54b4ec4-d527-4d08-997b-979a4e17e4e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "39036f51-9055-42c1-a607-95033185e143",
   "metadata": {},
   "source": [
    "Interpretation of the results:\n",
    "Positive Cohen's h: The proportion in the test group is larger than in the control group.\n",
    "Negative Cohen's h: The proportion in the test group is smaller than in the control group.\n",
    "\n",
    "M (Male): Cohen's h = 0.0040\n",
    "\n",
    "This is a very small positive value, indicating that the male proportion in the test group is slightly larger than in the control group, but the difference is tiny (almost negligible).\n",
    "\n",
    "F (Female): Cohen's h = -0.0248\n",
    "\n",
    "This small negative value means the female proportion in the test group is slightly smaller than in the control group. Again, the difference is very small.\n",
    "\n",
    "Unknown: Cohen's h = 0.0206\n",
    "\n",
    "This small positive value means the proportion of \"Unknown\" gender is slightly larger in the test group compared to the control group, but still very minor.\n",
    "\n",
    "\n",
    "Practical Significance:\n",
    "\n",
    "All values of Cohen's h are below 0.2, meaning these differences are very small and not practically significant.\n",
    "In summary, even though some of the proportions are statistically significantly different (as indicated by the p-values), the effect size (Cohen's h) shows that the differences are practically very minor, and likely not meaningful in a real-world context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c7c795-effe-4e1c-a03b-c48c9e47eac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we use T-test hypothesis to check if any of the below key continuous data columns has a distribution bias between test VS control group\n",
    "# tested columns \":tenure_years','age', 'acct_balance','num_accts','calls_6_mnth','logons_6_mnth' \n",
    "\n",
    "# H0: each one of them are equally distributed \n",
    "# H1: each one of them are not equally distributed \n",
    "\n",
    "from scipy.stats import ttest_ind\n",
    "t_stat, p_value = ttest_ind(df_control['tenure_years'],df_test['tenure_years'],equal_var=False)\n",
    "print(f\" column tenure_years t_stat:{t_stat}, p value:{p_value}\")\n",
    "#print (f\"above get p value =0.56 which means we fail to reject HO hypothsis,so this column is truely equally distributed\")\n",
    "\n",
    "t_stat, p_value = ttest_ind(df_control['age'],df_test['age'],equal_var=False)\n",
    "print(f\" column age t_stat:{t_stat}, p value:{p_value}\")\n",
    "# result: p_value <0.01\n",
    "\n",
    "t_stat, p_value = ttest_ind(df_control['acct_balance'],df_test['acct_balance'],equal_var=False)\n",
    "print(f\" column acct_balance t_stat:{t_stat}, p value:{p_value}\")\n",
    "# result: p_value <0.01\n",
    "\n",
    "t_stat, p_value = ttest_ind(df_control['num_accts'],df_test['num_accts'],equal_var=False)\n",
    "print(f\" column num_accts:{t_stat}, p value:{p_value}\")\n",
    "# result: p_value <0.01\n",
    "\n",
    "t_stat, p_value = ttest_ind(df_control['calls_6_mnth'],df_test['calls_6_mnth'],equal_var=False)\n",
    "print(f\" column calls_6_mnth:{t_stat}, p value:{p_value}\")\n",
    "# result: p_value <0.01\n",
    "\n",
    "t_stat, p_value = ttest_ind(df_control['logons_6_mnth'],df_test['logons_6_mnth'],equal_var=False)\n",
    "print(f\" column logons_6_mnth:{t_stat}, p value:{p_value}\")\n",
    "# result: p_value <0.01\n",
    "print(\"------------------------\")\n",
    "\n",
    "# for all above 5 columns which statistic P-value < 0.01 we are here to further check if bias distributed by compare each distinct value's percentage in each group:\n",
    "# below are general date to refer to\n",
    "\n",
    "#  column name:             value range                gap   \n",
    "# 'num_accts':              2-7\n",
    "# 'calls_6_mnth':           0-6l\n",
    "# 'logons_6_mnth':          3-9  \n",
    "# 'age' :              17-96                      79\n",
    "# 'acct_balance':                    23,789.61-- 8,292,996.21   8269207\n",
    "\n",
    "columns = ['num_accts','calls_6_mnth','logons_6_mnth']\n",
    "\n",
    "for col in columns:\n",
    "    control_counts = df_control[col].value_counts(normalize=True) * 100\n",
    "    control_counts = control_counts.rename(\"control_percentage\").reset_index()\n",
    "    control_counts = control_counts.rename(columns={\"index\": col})\n",
    "    test_counts = df_test[col].value_counts(normalize=True) * 100\n",
    "    test_counts = test_counts.rename(\"test_percentage\").reset_index()\n",
    "    test_counts = test_counts.rename(columns={\"index\": col})\n",
    "    combine_test_control_df = pd.merge(control_counts, test_counts, on=col, how='outer').fillna(0)\n",
    "    print(f\" percentage comparison for {col}\")\n",
    "    print(combine_test_control_df)\n",
    "    print(\"------------------------\")\n",
    "  \n",
    "\n",
    "# here continue check column 'clnt_age' if bias:\n",
    "control_age_groups = pd.cut(df_control['age'], bins=[17, 29, 39, 49, 59, 69, 79], labels=['17-29', '30-39', '40-49', '50-59', '60-69', '70-79'])\n",
    "test_age_groups = pd.cut(df_test['age'], bins=[17, 29, 39, 49, 59, 69, 79], labels=['17-29', '30-39', '40-49', '50-59', '60-69', '70-79'])\n",
    "\n",
    "control_age_counts = control_age_groups.value_counts(normalize=True) * 100\n",
    "control_age_counts = control_age_counts.rename(\"control_percentage\").reset_index()\n",
    "control_age_counts = control_age_counts.rename(columns={\"index\": \"age_group\"})\n",
    "test_age_counts = test_age_groups.value_counts(normalize=True) * 100\n",
    "test_age_counts = test_age_counts.rename(\"test_percentage\").reset_index()\n",
    "test_age_counts = test_age_counts.rename(columns={\"index\": \"age_group\"})\n",
    "clnt_age_test_control_df = pd.merge(control_age_counts, test_age_counts, on=\"age\",how='outer')\n",
    "clnt_age_test_control_df\n",
    "\n",
    "\n",
    "# here continue check column 'bal' if bias:\n",
    "control_bal_groups = pd.cut(df_control['acct_balance'], \n",
    "                            bins=[20000, 50000, 100000, 200000, 300000, 500000,1000000,9000000],\n",
    "                            labels=['20000-50000', '50001-100000', '100001-200000', '200001-300000', '300001-500000', '500001-1000000','1000001-9000000'])\n",
    "\n",
    "test_bal_groups = pd.cut(df_test['acct_balance'], \n",
    "                            bins=[20000, 50000, 100000, 200000, 300000, 500000,1000000,9000000],\n",
    "                            labels=['20000-50000', '50001-100000', '100001-200000', '200001-300000', '300001-500000', '500001-1000000','1000001-9000000'])\n",
    "\n",
    "control_bal_counts = control_bal_groups.value_counts(normalize=True) * 100\n",
    "control_bal_counts = control_bal_counts.rename(\"control_percentage\").reset_index()\n",
    "control_bal_counts = control_bal_counts.rename(columns={\"index\": \"bal_group\"})\n",
    "\n",
    "test_bal_counts = test_bal_groups.value_counts(normalize=True) * 100\n",
    "test_bal_counts = test_bal_counts.rename(\"test_percentage\").reset_index()\n",
    "test_bal_counts = test_bal_counts.rename(columns={\"index\": \"bal_group\"})\n",
    "test_bal_counts\n",
    "\n",
    "bal_test_control_df = pd.merge(control_bal_counts, test_bal_counts, on=\"acct_balance\",how='outer')\n",
    "print(bal_test_control_df)\n",
    "\n",
    "# All above futher check result shows in all key columns('gender','tenure_years','age', 'acct_balance','num_accts','calls_6_mnth','logons_6_mnth') \n",
    "# each distinct value's percentage gap between test VS control group are all less than 2% ,so we finally conclude : none of them is bias distributed. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3082721-f66f-407b-b54a-f7548b9b9d52",
   "metadata": {},
   "source": [
    "To check for practical significance, we calculate Cohen's d (similar to Cohen's h but with continuous variables). The formula for Cohen's D is:\n",
    "\n",
    "## Cohen's d Formula\r\n",
    "\r\n",
    "Cohen's $d$ is calculated as:\r\n",
    "\r\n",
    "$$\r\n",
    "d = \\frac{M_1 - M_2}{s}\r\n",
    "$$\r\n",
    "\r\n",
    "Where:\r\n",
    "- $M_1$ = Mean of the first group\r\n",
    "- $M_2$ = Mean of the second group\r\n",
    "- $s$ = Pooled standard deviation, calculated as:\r\n",
    "\r\n",
    "$$\r\n",
    "s = \\sqrt{\\frac{(n_1 - 1)s_1^2 + (n_2 - 1)s_2^2}{n_1 + n_2 - 2}}\r\n",
    "$$\r\n",
    "\r\n",
    "Where:\r\n",
    "- $n_1$ = Sample size of the first group\r\n",
    "- $n_2$ = Sample size of the second group\r\n",
    "- $s_1$ = Standard deviation of the first group\r\n",
    "- $s_2$ = Standard deviation of the second group\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69db810a-ad6b-4961-b483-215c4c20323f",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['tenure_years', 'age', 'acct_balance', 'num_accts', 'calls_6_mnth', 'logons_6_mnth']\n",
    "\n",
    "for col in columns:\n",
    "    # Ensure the values are numeric and remove any NaN values\n",
    "    control_data = pd.to_numeric(df_control[col], errors='coerce').dropna()\n",
    "    test_data = pd.to_numeric(df_test[col], errors='coerce').dropna()\n",
    "    \n",
    "    # Calculate Cohen's d\n",
    "    d_value = vf.cohen_d(control_data, test_data)\n",
    "    \n",
    "    print(f\"Cohen's d for {col}: {d_value:.4f}\")\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f11bb28-0360-4fef-a669-2ea0c2229454",
   "metadata": {},
   "source": [
    "From this output, you can see that while the differences were statistically significant from their p-values, the Cohen's d value for the columns is small, suggesting that the difference between the control and test groups is minimal in terms of effect size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1dbc603-8fe8-40b9-9e2d-8a13d788bf07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How do clients navigate through the old versus the new digital process? Do they follow similar steps or diverge at certain points?\n",
    "\n",
    "# Calculate the total number of errors for each group\n",
    "total_errors_control = df_sorted_control['is_back'].sum()\n",
    "total_errors_test = df_sorted_test['is_back'].sum()\n",
    "\n",
    "# Count backward steps for control group\n",
    "back_counts_control = df_sorted_control['back_label'].value_counts().fillna(0)\n",
    "\n",
    "# Count backward steps for test group\n",
    "back_counts_test = df_sorted_test['back_label'].value_counts().fillna(0)\n",
    "\n",
    "# Calculate the percentage of each backward step from the total errors\n",
    "back_ratio_control = (back_counts_control / total_errors_control * 100).round(1).astype(str) + '%'\n",
    "back_ratio_test = (back_counts_test / total_errors_test * 100).round(1).astype(str) + '%'\n",
    "\n",
    "# Create result DataFrames with updated back ratios\n",
    "result_control = pd.DataFrame({'back_count_control': back_counts_control, 'back_ratio_control': back_ratio_control})\n",
    "result_test = pd.DataFrame({'back_count_test': back_counts_test, 'back_ratio_test': back_ratio_test})\n",
    "\n",
    "# Combine results into a single DataFrame\n",
    "df_combined_bonus = pd.merge(result_test, result_control, on='back_label', how='outer')\n",
    "\n",
    "# Convert back ratios to float for normalization\n",
    "df_combined_bonus['back_ratio_test'] = df_combined_bonus['back_ratio_test'].str.rstrip('%').astype('float') / 100.0\n",
    "df_combined_bonus['back_ratio_control'] = df_combined_bonus['back_ratio_control'].str.rstrip('%').astype('float') / 100.0\n",
    "\n",
    "# Normalizing to make percentages add up to 100%\n",
    "df_combined_bonus['back_ratio_test'] = df_combined_bonus['back_ratio_test'] * 100 / df_combined_bonus['back_ratio_test'].sum()\n",
    "df_combined_bonus['back_ratio_control'] = df_combined_bonus['back_ratio_control'] * 100 / df_combined_bonus['back_ratio_control'].sum()\n",
    "\n",
    "# Prepare for plotting\n",
    "labels = df_combined_bonus.index.tolist()  \n",
    "x = np.arange(len(labels)) \n",
    "width = 0.35  \n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7, 3))\n",
    "\n",
    "# Create the bars\n",
    "bar1 = ax.bar(x - width/2, df_combined_bonus['back_ratio_test'], width, label='Test', color='skyblue')\n",
    "bar2 = ax.bar(x + width/2, df_combined_bonus['back_ratio_control'], width, label='Control', color='lightcoral')\n",
    "\n",
    "# Update axis labels and title\n",
    "ax.set_xlabel('Backward Steps')\n",
    "ax.set_ylabel('Ratio of Total Errors (%)')\n",
    "ax.set_title('Backward (Error) Ratio by Step for Test and Control Groups')\n",
    "ax.set_xticks(x)  \n",
    "ax.set_xticklabels(labels) \n",
    "ax.legend(title='Group')  \n",
    "\n",
    "# Function to add percentage labels on the bars\n",
    "def add_labels(bars):\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax.annotate(f'{height:.1f}%',  \n",
    "                    xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                    xytext=(0, 3),  \n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom')\n",
    "\n",
    "# Add labels to the bars\n",
    "add_labels(bar1)\n",
    "add_labels(bar2)\n",
    "\n",
    "# Set y-axis to show percentage scale\n",
    "ax.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, _: '{:.0f}%'.format(x)))\n",
    "\n",
    "plt.ylim(0, 100)  # Set y-axis limits from 0 to 100%\n",
    "\n",
    "plt.savefig('step_error_ratio.png', bbox_inches='tight', dpi=300)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e0b4e4-dc0e-46ee-8026-09118297f8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "As we can see here, the most errors in the new design are made at step 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e126ef9d-82c2-46aa-a013-d0976a31cddb",
   "metadata": {},
   "source": [
    "## CREATING A COMPREHENSIVE DATAFRAME WITH EVERYTHING FOR TABLEAU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9154e1f8-d7f8-4baf-a3ad-dcb62e913b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df_timesort = pd.concat([df_control_timesort, df_test_timesort], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748fe441-3ab9-44d1-89e7-36cce7ecd248",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df_timesort['acct_balance'] = combined_df_timesort['acct_balance'].round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1c691e-fb16-40ae-8331-2aa58855a862",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df_timesort['date_time'] = pd.to_datetime(combined_df_timesort['date_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd54ba9-c8cb-4309-8436-7e052b888202",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df_timesort.to_csv('combined_df_timesort.csv', sep=';', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
